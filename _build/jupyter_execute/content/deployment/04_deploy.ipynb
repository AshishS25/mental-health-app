{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Experiments\n",
    "\n",
    "This section covers various experiments performed using different models and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_and_preprocess_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 78\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest F1 Score with loaded model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 78\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[1], line 54\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# Load your preprocessed data\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     df \u001b[38;5;241m=\u001b[39m load_and_preprocess_data()\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Prepare features and target\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msought_treatment\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_and_preprocess_data' is not defined"
     ]
    }
   ],
   "source": [
    "#Save the model in joblib\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def create_final_pipeline():\n",
    "    \"\"\"Create the final pipeline with MinMax scaler\"\"\"\n",
    "    numeric_features = ['age', 'is_tech_company']\n",
    "    categorical_features = ['gender', 'country', 'company_size', 'work_remotely', \n",
    "                          'has_mental_health_benefits', 'current_disorder']\n",
    "    \n",
    "    # Create preprocessing pipelines\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', MinMaxScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "    ])\n",
    "    \n",
    "    # Combine preprocessing steps\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "    \n",
    "    # Create full pipeline\n",
    "    return Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(random_state=42))\n",
    "    ])\n",
    "\n",
    "def train_and_save_model(X_train, y_train, model_path='final_mental_health_model.joblib'):\n",
    "    \"\"\"Train and save the final model\"\"\"\n",
    "    # Create pipeline\n",
    "    pipeline = create_final_pipeline()\n",
    "    \n",
    "    # Fit the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Save the model\n",
    "    joblib.dump(pipeline, model_path)\n",
    "    print(f\"Model saved successfully to: {model_path}\")\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "def main():\n",
    "    # Load your preprocessed data\n",
    "    df = load_and_preprocess_data()\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = df.drop('sought_treatment', axis=1)\n",
    "    y = df['sought_treatment']\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Train and save model\n",
    "    final_model = train_and_save_model(X_train, y_train)\n",
    "    \n",
    "    # Verify the saved model\n",
    "    loaded_model = joblib.load('final_mental_health_model.joblib')\n",
    "    test_pred = loaded_model.predict(X_test)\n",
    "    test_score = f1_score(y_test, test_pred)\n",
    "    \n",
    "    print(\"\\nModel Verification:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Test F1 Score with loaded model: {test_score:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastAPI Development\n",
    "\n",
    "This section details the API development process using FastAPI.\n",
    "Navigate: [Previous (Feature Engineering)](03_feature_engineering.ipynb) | [Next (Streamlit Application)](05_streamlit_app.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#FastAPI code main.py\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd  # Add pandas import\n",
    "from fastapi.middleware.cors import CORSMiddleware \n",
    "import uvicorn\n",
    "\n",
    "# Create FastAPI app\n",
    "app = FastAPI(title=\"Mental Health Treatment Prediction API\")\n",
    "\n",
    "# Add CORS middleware to allow Streamlit app to make requests\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # Allow all origins; for production, restrict to specific domain\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# Load the saved model\n",
    "model = joblib.load('final_mental_health_model.joblib')\n",
    "#model = joblib.load(r'C:\\Users\\ASHISH\\mental_app\\final_mental_health_model.joblib')\n",
    "\n",
    "# Define input data structure\n",
    "class PredictionInput(BaseModel):\n",
    "    age: int\n",
    "    gender: str\n",
    "    country: str\n",
    "    company_size: str\n",
    "    is_tech_company: int\n",
    "    work_remotely: str\n",
    "    has_mental_health_benefits: str\n",
    "    current_disorder: str\n",
    "\n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"age\": 30,\n",
    "                \"gender\": \"male\",\n",
    "                \"country\": \"United States\",\n",
    "                \"company_size\": \"26-100\",\n",
    "                \"is_tech_company\": 1,\n",
    "                \"work_remotely\": \"sometimes\",\n",
    "                \"has_mental_health_benefits\": \"yes\",\n",
    "                \"current_disorder\": \"no\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "class PredictionOutput(BaseModel):\n",
    "    likelihood: float\n",
    "    prediction: str\n",
    "    probability: float\n",
    "\n",
    "@app.get(\"/\")\n",
    "def home():\n",
    "    return {\"message\": \"Mental Health Treatment Prediction API\", \n",
    "            \"health_check\": \"OK\"}\n",
    "\n",
    "@app.post(\"/predict\", response_model=PredictionOutput)\n",
    "def predict(data: PredictionInput):\n",
    "    try:\n",
    "        # Convert input data to DataFrame\n",
    "        input_df = pd.DataFrame([{\n",
    "            'age': data.age,\n",
    "            'gender': data.gender,\n",
    "            'country': data.country,\n",
    "            'company_size': data.company_size,\n",
    "            'is_tech_company': data.is_tech_company,\n",
    "            'work_remotely': data.work_remotely,\n",
    "            'has_mental_health_benefits': data.has_mental_health_benefits,\n",
    "            'current_disorder': data.current_disorder\n",
    "        }])\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(input_df)[0]\n",
    "        probability = model.predict_proba(input_df)[0][1]\n",
    "        \n",
    "        # Create response\n",
    "        response = {\n",
    "            \"likelihood\": probability,\n",
    "            \"prediction\": \"Likely to seek treatment\" if prediction == 1 else \"Unlikely to seek treatment\",\n",
    "            \"probability\": round(float(probability), 3)\n",
    "        }\n",
    "        \n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(\"main:app\", host=\"0.0.0.0\", port=8000, reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}