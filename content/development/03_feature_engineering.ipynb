{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "This section explains the feature engineering process and selection methods used.\n",
    "Navigate: [Previous (Model Development)](02_model_development.ipynb) | [Next (API Deployment)](04_deploy.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Experiment 3\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up MLflow\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'ashiashish100'\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = '7af28a60cc2f6e231f6413c9b48e241766a2e931'\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/ashiashish100/my-first-repo.mlflow\")\n",
    "mlflow.set_experiment(\"mental_health_feature_engineering\")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_base_data():\n",
    "    conn = sqlite3.connect('mental_health_final.db')\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        e.age,\n",
    "        e.gender,\n",
    "        e.country,\n",
    "        emp.company_size,\n",
    "        emp.is_tech_company,\n",
    "        emp.work_remotely,\n",
    "        mhb.has_mental_health_benefits,\n",
    "        mhh.current_disorder,\n",
    "        mhh.sought_treatment,\n",
    "        wc.discuss_with_supervisor,\n",
    "        wc.discuss_with_coworkers,\n",
    "        wc.observed_negative_consequences,\n",
    "        wc.interferes_with_work\n",
    "    FROM employees e\n",
    "    LEFT JOIN employment emp ON e.employee_id = emp.employee_id\n",
    "    LEFT JOIN mental_health_benefits mhb ON e.employee_id = mhb.employee_id\n",
    "    LEFT JOIN mental_health_history mhh ON e.employee_id = mhh.employee_id\n",
    "    LEFT JOIN workplace_communication wc ON e.employee_id = wc.employee_id\n",
    "    \"\"\"\n",
    "    return pd.read_sql_query(query, conn)\n",
    "\n",
    "def engineer_features(df):\n",
    "    #Perform feature engineering\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Age-based features\n",
    "    df['age_group'] = pd.qcut(df['age'], q=5, labels=['very_young', 'young', 'middle', 'senior', 'very_senior'])\n",
    "    \n",
    "    # 2. Company size normalization\n",
    "    size_map = {\n",
    "        '1-25': 1,\n",
    "        '26-100': 2,\n",
    "        '100-500': 3,\n",
    "        '500-1000': 4,\n",
    "        '1000+': 5\n",
    "    }\n",
    "    df['company_size_normalized'] = df['company_size'].map(size_map)\n",
    "    \n",
    "    # 3. Communication comfort score\n",
    "    df['communication_score'] = 0\n",
    "    df.loc[df['discuss_with_supervisor'] == 'yes', 'communication_score'] += 1\n",
    "    df.loc[df['discuss_with_coworkers'] == 'yes', 'communication_score'] += 1\n",
    "    \n",
    "    # 4. Remote work interaction\n",
    "    df['remote_with_benefits'] = ((df['work_remotely'] != 'never') & \n",
    "                                 (df['has_mental_health_benefits'] == 'yes')).astype(int)\n",
    "    \n",
    "    # 5. Tech environment score\n",
    "    df['tech_environment_score'] = df['is_tech_company'] * df['company_size_normalized']\n",
    "    \n",
    "    # 6. Workplace support index\n",
    "    df['workplace_support_index'] = (\n",
    "        (df['has_mental_health_benefits'] == 'yes').astype(int) +\n",
    "        (df['discuss_with_supervisor'] == 'yes').astype(int) +\n",
    "        (df['observed_negative_consequences'] == 'no').astype(int)\n",
    "    )\n",
    "    \n",
    "    # 7. Work impact indicator\n",
    "    df['work_impact_severity'] = pd.Categorical(\n",
    "        df['interferes_with_work'],\n",
    "        categories=['never', 'rarely', 'sometimes', 'often', 'always'],\n",
    "        ordered=True\n",
    "    ).codes\n",
    "    \n",
    "    # Handle missing values\n",
    "    df = handle_missing_values(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def handle_missing_values(df):\n",
    "    #Handle missing values in the dataset\n",
    "    # Numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    for col in numeric_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    # Categorical columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].fillna('unknown')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_feature_sets():\n",
    "    #Create different feature sets for experimentation\n",
    "    feature_sets = {\n",
    "        'base_features': [\n",
    "            'age', 'gender', 'country', 'company_size', 'is_tech_company', \n",
    "            'work_remotely', 'has_mental_health_benefits', 'current_disorder'\n",
    "        ],\n",
    "        \n",
    "        'engineered_only': [\n",
    "            'age_group', 'company_size_normalized', 'communication_score',\n",
    "            'remote_with_benefits', 'tech_environment_score', \n",
    "            'workplace_support_index', 'work_impact_severity'\n",
    "        ],\n",
    "        \n",
    "        'combined_features': [\n",
    "            'age', 'gender', 'country', 'is_tech_company', 'work_remotely',\n",
    "            'company_size_normalized', 'communication_score',\n",
    "            'workplace_support_index', 'work_impact_severity',\n",
    "            'tech_environment_score'\n",
    "        ],\n",
    "        \n",
    "        'communication_focused': [\n",
    "            'discuss_with_supervisor', 'discuss_with_coworkers',\n",
    "            'observed_negative_consequences', 'interferes_with_work',\n",
    "            'communication_score', 'workplace_support_index'\n",
    "        ]\n",
    "    }\n",
    "    return feature_sets\n",
    "\n",
    "def run_experiment(X, y, feature_set_name, features):\n",
    "    #Run experiment with specific feature set\n",
    "    with mlflow.start_run(run_name=f\"feature_eng_{feature_set_name}\"):\n",
    "        # Log feature set\n",
    "        mlflow.log_param(\"feature_set\", feature_set_name)\n",
    "        mlflow.log_param(\"n_features\", len(features))\n",
    "        mlflow.log_param(\"features\", \", \".join(features))\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X[features], y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Create preprocessing pipeline\n",
    "        numeric_features = X[features].select_dtypes(include=['int64', 'float64']).columns\n",
    "        categorical_features = X[features].select_dtypes(include=['object']).columns\n",
    "        \n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', StandardScaler(), numeric_features),\n",
    "                ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "            ])\n",
    "        \n",
    "        # Create and train pipeline\n",
    "        model = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', LogisticRegression(random_state=42))\n",
    "        ])\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1')\n",
    "        \n",
    "        # Train and evaluate\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'f1_score': f1_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred)\n",
    "        }\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"cv_f1_mean\", cv_scores.mean())\n",
    "        mlflow.log_metric(\"cv_f1_std\", cv_scores.std())\n",
    "        for metric_name, metric_value in metrics.items():\n",
    "            mlflow.log_metric(f\"test_{metric_name}\", metric_value)\n",
    "        \n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        # Print results\n",
    "        logger.info(f\"\\nResults for {feature_set_name}:\")\n",
    "        logger.info(f\"CV F1-Score: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "        logger.info(\"Test Metrics:\")\n",
    "        for metric_name, metric_value in metrics.items():\n",
    "            logger.info(f\"{metric_name}: {metric_value:.4f}\")\n",
    "        \n",
    "        return model, metrics\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "    logger.info(\"Loading data...\")\n",
    "    df = load_base_data()\n",
    "    \n",
    "    # Engineer features\n",
    "    logger.info(\"Engineering features...\")\n",
    "    df_engineered = engineer_features(df)\n",
    "    \n",
    "    # Prepare target\n",
    "    y = df_engineered['sought_treatment']\n",
    "    \n",
    "    # Get feature sets\n",
    "    feature_sets = create_feature_sets()\n",
    "    \n",
    "    # Run experiments for each feature set\n",
    "    for set_name, features in feature_sets.items():\n",
    "        logger.info(f\"\\nRunning experiment with {set_name}\")\n",
    "        run_experiment(df_engineered, y, set_name, features)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Experiment 4\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import logging\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up MLflow\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'ashiashish100'\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = '7af28a60cc2f6e231f6413c9b48e241766a2e931'\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/ashiashish100/my-first-repo.mlflow\")\n",
    "mlflow.set_experiment(\"mental_health_feature_selection\")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_data():\n",
    "    conn = sqlite3.connect('mental_health_final.db')\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        e.age,\n",
    "        e.gender,\n",
    "        e.country,\n",
    "        emp.company_size,\n",
    "        emp.is_tech_company,\n",
    "        emp.work_remotely,\n",
    "        mhb.has_mental_health_benefits,\n",
    "        mhh.current_disorder,\n",
    "        mhh.sought_treatment,\n",
    "        wc.discuss_with_supervisor,\n",
    "        wc.discuss_with_coworkers,\n",
    "        wc.observed_negative_consequences,\n",
    "        wc.interferes_with_work\n",
    "    FROM employees e\n",
    "    LEFT JOIN employment emp ON e.employee_id = emp.employee_id\n",
    "    LEFT JOIN mental_health_benefits mhb ON e.employee_id = mhb.employee_id\n",
    "    LEFT JOIN mental_health_history mhh ON e.employee_id = mhh.employee_id\n",
    "    LEFT JOIN workplace_communication wc ON e.employee_id = wc.employee_id\n",
    "    \"\"\"\n",
    "    return pd.read_sql_query(query, conn)\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Handle missing values\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].fillna('unknown')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def correlation_based_selection(X, y, threshold=0.1):\n",
    "    #Select features based on correlation with target\n",
    "    # Create a copy of the dataframe\n",
    "    X_processed = X.copy()\n",
    "    \n",
    "    # Process numeric columns only\n",
    "    numeric_cols = X_processed.select_dtypes(include=['int64', 'float64']).columns\n",
    "    \n",
    "    # Calculate correlations for numeric features only\n",
    "    correlations = []\n",
    "    for col in numeric_cols:\n",
    "        corr = abs(np.corrcoef(X_processed[col], y)[0, 1])\n",
    "        correlations.append((col, corr))\n",
    "    \n",
    "    # Sort by correlation\n",
    "    correlations.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Select features above threshold\n",
    "    selected_features = [col for col, corr in correlations if corr > threshold]\n",
    "    \n",
    "    # Add categorical columns that might be important\n",
    "    categorical_cols = X_processed.select_dtypes(include=['object']).columns\n",
    "    selected_features.extend(categorical_cols)\n",
    "    \n",
    "    # Ensure at least some features are selected\n",
    "    if not selected_features:\n",
    "        # Take top 5 features if none meet threshold\n",
    "        selected_features = [col for col, _ in correlations[:5]]\n",
    "        selected_features.extend(categorical_cols)\n",
    "    \n",
    "    logger.info(f\"Number of features selected: {len(selected_features)}\")\n",
    "    logger.info(f\"Selected features: {selected_features}\")\n",
    "    \n",
    "    return list(set(selected_features)), correlations\n",
    "\n",
    "def variance_based_selection(X, threshold=0.01):\n",
    "    #Select features based on variance\n",
    "    selector = VarianceThreshold(threshold=threshold)\n",
    "    \n",
    "    # Apply to numeric features only\n",
    "    numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    selector.fit(X[numeric_cols])\n",
    "    \n",
    "    # Get selected features\n",
    "    selected_features = numeric_cols[selector.get_support()].tolist()\n",
    "    \n",
    "    return selected_features, selector\n",
    "\n",
    "def importance_based_selection(X, y, n_features=10):\n",
    "    #Select features based on importance scores\n",
    "    # Create a copy for preprocessing\n",
    "    X_processed = X.copy()\n",
    "    \n",
    "    # Get numeric and categorical columns\n",
    "    numeric_features = X_processed.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = X_processed.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Handle categorical features\n",
    "    for col in categorical_features:\n",
    "        # Convert to categorical codes\n",
    "        X_processed[col] = pd.Categorical(X_processed[col]).codes\n",
    "    \n",
    "    # Create and fit random forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_processed, y)\n",
    "    \n",
    "    # Get feature importance scores\n",
    "    importances = list(zip(X.columns, rf.feature_importances_))\n",
    "    importances.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Select top n features\n",
    "    selected_features = [feat for feat, imp in importances[:n_features]]\n",
    "    \n",
    "    logger.info(f\"Top {n_features} important features:\")\n",
    "    for feat, imp in importances[:n_features]:\n",
    "        logger.info(f\"{feat}: {imp:.4f}\")\n",
    "    \n",
    "    return selected_features, importances\n",
    "\n",
    "def run_experiment(X, y, selected_features, selection_method):\n",
    "    #Run experiment with selected features\n",
    "    # Check if we have features selected\n",
    "    if not selected_features:\n",
    "        logger.error(f\"No features selected for {selection_method}\")\n",
    "        return None, None\n",
    "        \n",
    "    with mlflow.start_run(run_name=f\"feature_selection_{selection_method}\"):\n",
    "        try:\n",
    "            # Log parameters\n",
    "            mlflow.log_param(\"selection_method\", selection_method)\n",
    "            mlflow.log_param(\"n_selected_features\", len(selected_features))\n",
    "            mlflow.log_param(\"selected_features\", \", \".join(selected_features))\n",
    "            \n",
    "            # Split data\n",
    "            X_selected = X[selected_features]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_selected, y, test_size=0.2, random_state=42, stratify=y\n",
    "            )\n",
    "            \n",
    "            # Create pipeline\n",
    "            numeric_features = X_selected.select_dtypes(include=['int64', 'float64']).columns\n",
    "            categorical_features = X_selected.select_dtypes(include=['object']).columns\n",
    "            \n",
    "            transformers = []\n",
    "            if len(numeric_features) > 0:\n",
    "                transformers.append(('num', StandardScaler(), numeric_features))\n",
    "            if len(categorical_features) > 0:\n",
    "                transformers.append(('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features))\n",
    "            \n",
    "            preprocessor = ColumnTransformer(transformers=transformers)\n",
    "            \n",
    "            model = Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('classifier', LogisticRegression(random_state=42))\n",
    "            ])\n",
    "            \n",
    "            # Cross-validation with error handling\n",
    "            try:\n",
    "                cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1')\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Cross-validation failed: {str(e)}\")\n",
    "                cv_scores = np.array([0])\n",
    "            \n",
    "            # Train and evaluate\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = {\n",
    "                'accuracy': accuracy_score(y_test, y_pred),\n",
    "                'f1_score': f1_score(y_test, y_pred),\n",
    "                'precision': precision_score(y_test, y_pred),\n",
    "                'recall': recall_score(y_test, y_pred)\n",
    "            }\n",
    "            \n",
    "            # Log metrics\n",
    "            mlflow.log_metric(\"cv_f1_mean\", cv_scores.mean())\n",
    "            mlflow.log_metric(\"cv_f1_std\", cv_scores.std())\n",
    "            for metric_name, metric_value in metrics.items():\n",
    "                mlflow.log_metric(f\"test_{metric_name}\", metric_value)\n",
    "            \n",
    "            # Log model\n",
    "            mlflow.sklearn.log_model(model, \"model\")\n",
    "            \n",
    "            # Print results\n",
    "            logger.info(f\"\\nResults for {selection_method}:\")\n",
    "            logger.info(f\"Number of selected features: {len(selected_features)}\")\n",
    "            logger.info(f\"Selected features: {selected_features}\")\n",
    "            logger.info(f\"CV F1-Score: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "            logger.info(\"Test Metrics:\")\n",
    "            for metric_name, metric_value in metrics.items():\n",
    "                logger.info(f\"{metric_name}: {metric_value:.4f}\")\n",
    "            \n",
    "            return model, metrics\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in experiment {selection_method}: {str(e)}\")\n",
    "            return None, None\n",
    "\n",
    "def plot_feature_importance(importances, title=\"Feature Importance\"):\n",
    "    #Plot feature importance scores\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    importance_df = pd.DataFrame(importances, columns=['feature', 'importance'])\n",
    "    sns.barplot(x='importance', y='feature', data=importance_df)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance.png')\n",
    "    return 'feature_importance.png'\n",
    "\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    logger.info(\"Loading data...\")\n",
    "    df = load_data()\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = df.drop('sought_treatment', axis=1)\n",
    "    y = df['sought_treatment']\n",
    "    \n",
    "    # 1. Correlation-based selection\n",
    "    logger.info(\"\\nPerforming correlation-based selection...\")\n",
    "    corr_features, correlations = correlation_based_selection(X, y, threshold=0.3)\n",
    "    run_experiment(X, y, corr_features, \"correlation_based\")\n",
    "    \n",
    "    # 2. Variance-based selection\n",
    "    logger.info(\"\\nPerforming variance-based selection...\")\n",
    "    var_features, var_selector = variance_based_selection(X, threshold=0.01)\n",
    "    run_experiment(X, y, var_features, \"variance_based\")\n",
    "    \n",
    "    # 3. Importance-based selection\n",
    "    logger.info(\"\\nPerforming importance-based selection...\")\n",
    "    imp_features, importances = importance_based_selection(X, y, n_features=10)\n",
    "    \n",
    "    # Plot and log feature importance\n",
    "    with mlflow.start_run(run_name=\"feature_importance_analysis\"):\n",
    "        importance_plot = plot_feature_importance(importances)\n",
    "        mlflow.log_artifact(importance_plot)\n",
    "    \n",
    "    run_experiment(X, y, imp_features, \"importance_based\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Experiment 5\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set up MLflow tracking\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'ashiashish100'\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = '7af28a60cc2f6e231f6413c9b48e241766a2e931'\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/ashiashish100/my-first-repo.mlflow\")\n",
    "mlflow.set_experiment(\"mental_health_pca\")\n",
    "\n",
    "def load_data():\n",
    "    #Load data from database\n",
    "    conn = sqlite3.connect('mental_health_final.db')\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            e.age,\n",
    "            e.gender,\n",
    "            e.country,\n",
    "            emp.company_size,\n",
    "            emp.is_tech_company,\n",
    "            emp.work_remotely,\n",
    "            mhb.has_mental_health_benefits,\n",
    "            mhh.current_disorder,\n",
    "            mhh.sought_treatment,\n",
    "            wc.discuss_with_supervisor,\n",
    "            wc.discuss_with_coworkers,\n",
    "            wc.observed_negative_consequences,\n",
    "            wc.interferes_with_work\n",
    "        FROM employees e\n",
    "        LEFT JOIN employment emp ON e.employee_id = emp.employee_id\n",
    "        LEFT JOIN mental_health_benefits mhb ON e.employee_id = mhb.employee_id\n",
    "        LEFT JOIN mental_health_history mhh ON e.employee_id = mhh.employee_id\n",
    "        LEFT JOIN workplace_communication wc ON e.employee_id = wc.employee_id\n",
    "        \"\"\"\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading data from database: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "def standardize_gender(df):\n",
    "    #Standardize gender categories\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    df['gender'] = df['gender'].str.lower()\n",
    "    \n",
    "    # Create mapping for gender standardization\n",
    "    gender_map = {\n",
    "        'male': 'male',\n",
    "        'm': 'male',\n",
    "        'man': 'male',\n",
    "        'cis male': 'male',\n",
    "        'male ': 'male',\n",
    "        'cisdude': 'male',\n",
    "        'm|': 'male',\n",
    "        'female': 'female',\n",
    "        'f': 'female',\n",
    "        'woman': 'female',\n",
    "        'cis female': 'female',\n",
    "        'female ': 'female'\n",
    "    }\n",
    "    \n",
    "    # Apply mapping and group all other values as 'other'\n",
    "    df['gender'] = df['gender'].apply(lambda x: gender_map.get(str(x).lower(), 'other'))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    #Preprocess the data\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Standardize gender\n",
    "    df = standardize_gender(df)\n",
    "    \n",
    "    # Handle missing values\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].fillna('unknown')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_scree_plot(explained_variance_ratio):\n",
    "    #Create and save scree plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(explained_variance_ratio) + 1), \n",
    "             explained_variance_ratio, 'bo-')\n",
    "    plt.plot(range(1, len(explained_variance_ratio) + 1),\n",
    "             np.cumsum(explained_variance_ratio), 'ro-')\n",
    "    plt.xlabel('Principal Component')\n",
    "    plt.ylabel('Explained Variance Ratio')\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xticks(range(1, len(explained_variance_ratio) + 1))\n",
    "    plt.legend(['Individual', 'Cumulative'])\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plt.savefig('scree_plot.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return 'scree_plot.png'\n",
    "\n",
    "def select_n_components(explained_variance_ratio, threshold=0.95):\n",
    "    #Select number of components based on cumulative explained variance\n",
    "    cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "    n_components = np.argmax(cumulative_variance_ratio >= threshold) + 1\n",
    "    return n_components\n",
    "\n",
    "def run_pca_experiment(X, y):\n",
    "    #Run PCA experiment with automatic component selection\n",
    "    with mlflow.start_run(run_name=\"pca_analysis\"):\n",
    "        try:\n",
    "            # Preprocess data first\n",
    "            X = preprocess_data(X)\n",
    "            \n",
    "            # Create preprocessing pipeline for all features\n",
    "            numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "            categorical_features = X.select_dtypes(include=['object']).columns\n",
    "            \n",
    "            # Create preprocessor with handle_unknown='ignore'\n",
    "            preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('num', StandardScaler(), numeric_features),\n",
    "                    ('cat', OneHotEncoder(drop='first', sparse=False, handle_unknown='ignore'), categorical_features)\n",
    "                ])\n",
    "            \n",
    "            # Fit preprocessor and transform data\n",
    "            X_preprocessed = preprocessor.fit_transform(X)\n",
    "            \n",
    "            # Perform PCA\n",
    "            pca = PCA()\n",
    "            X_pca = pca.fit_transform(X_preprocessed)\n",
    "            \n",
    "            # Create and save scree plot\n",
    "            scree_plot_path = create_scree_plot(pca.explained_variance_ratio_)\n",
    "            mlflow.log_artifact(scree_plot_path)\n",
    "            \n",
    "            # Select number of components\n",
    "            n_components = select_n_components(pca.explained_variance_ratio_)\n",
    "            logger.info(f\"Selected {n_components} components explaining 95% of variance\")\n",
    "            \n",
    "            # Log PCA information\n",
    "            mlflow.log_param(\"n_components\", n_components)\n",
    "            mlflow.log_metric(\"explained_variance_ratio\", \n",
    "                             np.sum(pca.explained_variance_ratio_[:n_components]))\n",
    "            \n",
    "            # Create final pipeline with selected components\n",
    "            pca_pipeline = Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('pca', PCA(n_components=n_components)),\n",
    "                ('classifier', LogisticRegression(random_state=42))\n",
    "            ])\n",
    "            \n",
    "            # Split data\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42, stratify=y\n",
    "            )\n",
    "            \n",
    "            # Perform cross-validation\n",
    "            cv_scores = cross_val_score(pca_pipeline, X_train, y_train, cv=5, scoring='f1')\n",
    "            \n",
    "            # Train final model\n",
    "            pca_pipeline.fit(X_train, y_train)\n",
    "            y_pred = pca_pipeline.predict(X_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = {\n",
    "                'accuracy': accuracy_score(y_test, y_pred),\n",
    "                'f1_score': f1_score(y_test, y_pred),\n",
    "                'precision': precision_score(y_test, y_pred),\n",
    "                'recall': recall_score(y_test, y_pred)\n",
    "            }\n",
    "            \n",
    "            # Log metrics\n",
    "            mlflow.log_metric(\"cv_f1_mean\", cv_scores.mean())\n",
    "            mlflow.log_metric(\"cv_f1_std\", cv_scores.std())\n",
    "            for metric_name, metric_value in metrics.items():\n",
    "                mlflow.log_metric(f\"test_{metric_name}\", metric_value)\n",
    "            \n",
    "            # Log model\n",
    "            mlflow.sklearn.log_model(pca_pipeline, \"model\")\n",
    "            \n",
    "            # Create component analysis plot\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            component_variance = pd.DataFrame({\n",
    "                'Component': range(1, len(pca.explained_variance_ratio_) + 1),\n",
    "                'Explained Variance': pca.explained_variance_ratio_\n",
    "            })\n",
    "            sns.barplot(data=component_variance.head(10), \n",
    "                       x='Component', y='Explained Variance')\n",
    "            plt.title('Top 10 Principal Components - Explained Variance')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('component_analysis.png')\n",
    "            mlflow.log_artifact('component_analysis.png')\n",
    "            plt.close()\n",
    "            \n",
    "            # Print results\n",
    "            logger.info(\"\\nPCA Results:\")\n",
    "            logger.info(f\"Number of components selected: {n_components}\")\n",
    "            logger.info(f\"Total explained variance: {np.sum(pca.explained_variance_ratio_[:n_components]):.4f}\")\n",
    "            logger.info(f\"CV F1-Score: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "            logger.info(\"Test Metrics:\")\n",
    "            for metric_name, metric_value in metrics.items():\n",
    "                logger.info(f\"{metric_name}: {metric_value:.4f}\")\n",
    "            \n",
    "            return pca_pipeline, metrics\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"An error occurred during PCA experiment: {e}\")\n",
    "            raise\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "    logger.info(\"Loading data...\")\n",
    "    df = load_data()\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = df.drop('sought_treatment', axis=1)\n",
    "    y = df['sought_treatment']\n",
    "    \n",
    "    # Run PCA experiment\n",
    "    logger.info(\"\\nRunning PCA experiment...\")\n",
    "    model, metrics = run_pca_experiment(X, y)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Experiment 6 & 7\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_recall_fscore_support, \n",
    "    confusion_matrix, \n",
    "    classification_report\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'ashiashish100'\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = '7af28a60cc2f6e231f6413c9b48e241766a2e931'\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/ashiashish100/my-first-repo.mlflow\")\n",
    "mlflow.set_experiment(\"mental_health_communication_factors\")\n",
    "\n",
    "def load_and_prepare_data():\n",
    "    # Database connection\n",
    "    conn = sqlite3.connect('mental_health_final.db')\n",
    "    \n",
    "    try:\n",
    "        # Comprehensive query to extract relevant features\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            e.age,\n",
    "            e.gender,\n",
    "            e.country,\n",
    "            emp.company_size,\n",
    "            emp.is_tech_company,\n",
    "            emp.work_remotely,\n",
    "            mhb.has_mental_health_benefits,\n",
    "            mhh.current_disorder,\n",
    "            mhh.sought_treatment,\n",
    "            wc.discuss_with_supervisor,\n",
    "            wc.discuss_with_coworkers,\n",
    "            wc.observed_negative_consequences,\n",
    "            wc.interferes_with_work\n",
    "        FROM employees e\n",
    "        LEFT JOIN employment emp ON e.employee_id = emp.employee_id\n",
    "        LEFT JOIN mental_health_benefits mhb ON e.employee_id = mhb.employee_id\n",
    "        LEFT JOIN mental_health_history mhh ON e.employee_id = mhh.employee_id\n",
    "        LEFT JOIN workplace_communication wc ON e.employee_id = wc.employee_id\n",
    "        \"\"\"\n",
    "        \n",
    "        # Read data\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        \n",
    "        # Separate features and target\n",
    "        X = df.drop('sought_treatment', axis=1)\n",
    "        y = df['sought_treatment']\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Data loading error: {e}\")\n",
    "        raise\n",
    "    \n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "def preprocess_data(X):\n",
    "    # Standardize gender\n",
    "    def standardize_gender(series):\n",
    "        gender_map = {\n",
    "            'male': 'male', 'm': 'male', 'man': 'male', \n",
    "            'cis male': 'male', 'male ': 'male', \n",
    "            'female': 'female', 'f': 'female', 'woman': 'female', \n",
    "            'cis female': 'female', 'female ': 'female'\n",
    "        }\n",
    "        return series.str.lower().map(lambda x: gender_map.get(x, 'other'))\n",
    "    \n",
    "    # Create a copy of the dataframe\n",
    "    df = X.copy()\n",
    "    \n",
    "    # Standardize gender column\n",
    "    df['gender'] = standardize_gender(df['gender'])\n",
    "    \n",
    "    # Handle missing values\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Fill numeric columns with median\n",
    "    for col in numeric_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    # Fill categorical columns with 'unknown'\n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].fillna('unknown')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_communication_interaction_features(X):\n",
    "    df = X.copy()\n",
    "    \n",
    "    # Ensure numeric conversion with error handling\n",
    "    def safe_numeric_convert(series):\n",
    "        try:\n",
    "            return pd.to_numeric(series, errors='coerce').fillna(0)\n",
    "        except Exception as e:\n",
    "            print(f\"Conversion error: {e}\")\n",
    "            return np.zeros(len(series))\n",
    "    \n",
    "    # Interaction between discussing with supervisor and coworkers\n",
    "    discuss_supervisor = safe_numeric_convert(df['discuss_with_supervisor'])\n",
    "    discuss_coworkers = safe_numeric_convert(df['discuss_with_coworkers'])\n",
    "    df['communication_openness'] = discuss_supervisor * discuss_coworkers\n",
    "    \n",
    "    # Workplace impact interaction\n",
    "    interferes_work = safe_numeric_convert(df['interferes_with_work'])\n",
    "    negative_consequences = safe_numeric_convert(df['observed_negative_consequences'])\n",
    "    df['workplace_mental_health_impact'] = interferes_work * negative_consequences\n",
    "    \n",
    "    return df\n",
    "\n",
    "def run_communication_experiment(X, y):\n",
    "    # Start MLflow run\n",
    "    with mlflow.start_run(run_name=\"communication_factors_analysis\"):\n",
    "        try:\n",
    "            # Preprocess data\n",
    "            X_processed = preprocess_data(X)\n",
    "            \n",
    "            # Create interaction features\n",
    "            X_with_interactions = create_communication_interaction_features(X_processed)\n",
    "            \n",
    "            # Identify feature types\n",
    "            numeric_features = X_with_interactions.select_dtypes(include=['int64', 'float64']).columns\n",
    "            categorical_features = X_with_interactions.select_dtypes(include=['object']).columns\n",
    "            \n",
    "            # Create preprocessing pipeline\n",
    "            preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('num', StandardScaler(), numeric_features),\n",
    "                    ('cat', OneHotEncoder(drop='first', sparse=False, handle_unknown='ignore'), categorical_features)\n",
    "                ])\n",
    "            \n",
    "            # Create full pipeline with Random Forest\n",
    "            pipeline = Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('classifier', RandomForestClassifier(\n",
    "                    n_estimators=100, \n",
    "                    random_state=42, \n",
    "                    class_weight='balanced'\n",
    "                ))\n",
    "            ])\n",
    "            \n",
    "            # Stratified K-Fold Cross-Validation\n",
    "            cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "            \n",
    "            # Perform cross-validation\n",
    "            cv_scores = cross_val_score(pipeline, X_with_interactions, y, cv=cv, scoring='f1')\n",
    "            \n",
    "            # Split data\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_with_interactions, y, test_size=0.2, stratify=y, random_state=42\n",
    "            )\n",
    "            \n",
    "            # Fit the pipeline\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            \n",
    "            # Predictions\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            \n",
    "            # Detailed metrics\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "            \n",
    "            # Confusion Matrix\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            \n",
    "            # Log metrics\n",
    "            mlflow.log_metrics({\n",
    "                'cv_f1_mean': cv_scores.mean(),\n",
    "                'cv_f1_std': cv_scores.std(),\n",
    "                'test_precision': precision,\n",
    "                'test_recall': recall,\n",
    "                'test_f1_score': f1\n",
    "            })\n",
    "            \n",
    "            # Feature importance visualization\n",
    "            feature_names = (\n",
    "                list(numeric_features) + \n",
    "                list(pipeline.named_steps['preprocessor']\n",
    "                     .named_transformers_['cat']\n",
    "                     .get_feature_names_out(categorical_features))\n",
    "            )\n",
    "            \n",
    "            # Extract feature importances\n",
    "            importances = pipeline.named_steps['classifier'].feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]\n",
    "            \n",
    "            # Plot feature importances\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.title(\"Feature Importances in Mental Health Treatment Seeking\")\n",
    "            plt.bar(range(len(importances)), importances[indices])\n",
    "            plt.xticks(range(len(importances)), \n",
    "                       [feature_names[i] for i in indices], \n",
    "                       rotation=90)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('feature_importances.png')\n",
    "            mlflow.log_artifact('feature_importances.png')\n",
    "            \n",
    "            # Confusion Matrix Visualization\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "            plt.title('Confusion Matrix')\n",
    "            plt.ylabel('True Label')\n",
    "            plt.xlabel('Predicted Label')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('confusion_matrix.png')\n",
    "            mlflow.log_artifact('confusion_matrix.png')\n",
    "            \n",
    "            # Log the model\n",
    "            mlflow.sklearn.log_model(pipeline, \"communication_factors_model\")\n",
    "            \n",
    "            # Print and log detailed results\n",
    "            logger.info(\"\\nExperiment Results:\")\n",
    "            logger.info(f\"Cross-Validation F1 Score: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "            logger.info(f\"Test Precision: {precision:.4f}\")\n",
    "            logger.info(f\"Test Recall: {recall:.4f}\")\n",
    "            logger.info(f\"Test F1 Score: {f1:.4f}\")\n",
    "            \n",
    "            # Classification Report\n",
    "            class_report = classification_report(y_test, y_pred)\n",
    "            logger.info(\"\\nClassification Report:\\n\" + class_report)\n",
    "            \n",
    "            return pipeline, {\n",
    "                'cv_f1_mean': cv_scores.mean(),\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1_score': f1\n",
    "            }\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Experiment failed: {e}\")\n",
    "            raise\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "    logger.info(\"Loading and preparing data...\")\n",
    "    X, y = load_and_prepare_data()\n",
    "    \n",
    "    # Run experiment\n",
    "    logger.info(\"\\nRunning communication factors experiment...\")\n",
    "    model, metrics = run_communication_experiment(X, y)\n",
    "    \n",
    "    return model, metrics\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#F1 score plots to compare and determin the best model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, FunctionTransformer, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def plot_f1_scores(results):\n",
    "    \"\"\"Create comparison plots for F1 scores\"\"\"\n",
    "    # Create figure with subplots\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # 1. Box plot of CV F1 scores\n",
    "    plt.subplot(2, 2, 1)\n",
    "    cv_data = []\n",
    "    labels = []\n",
    "    for scaler, result in results.items():\n",
    "        cv_data.extend(result['cv_scores'])\n",
    "        labels.extend([scaler] * len(result['cv_scores']))\n",
    "    \n",
    "    cv_df = pd.DataFrame({\n",
    "        'Scaler': labels,\n",
    "        'F1 Score': cv_data\n",
    "    })\n",
    "    \n",
    "    sns.boxplot(x='Scaler', y='F1 Score', data=cv_df, palette='Set2')\n",
    "    plt.title('Distribution of CV F1 Scores by Scaler', fontsize=14)\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 2. Bar plot with error bars\n",
    "    plt.subplot(2, 2, 2)\n",
    "    means = [result['cv_scores'].mean() for result in results.values()]\n",
    "    stds = [result['cv_scores'].std() for result in results.values()]\n",
    "    \n",
    "    bars = plt.bar(results.keys(), means, yerr=stds, capsize=5, color=['lightblue', 'lightgreen', 'salmon'])\n",
    "    plt.title('Mean CV F1 Scores with Standard Deviation', fontsize=14)\n",
    "    plt.xlabel('Scaler Type', fontsize=12)\n",
    "    plt.ylabel('F1 Score', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}',\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    # 3. Line plot showing CV scores across folds\n",
    "    plt.subplot(2, 2, 3)\n",
    "    markers = ['o', 's', '^']\n",
    "    colors = ['blue', 'green', 'red']\n",
    "    for (scaler, result), marker, color in zip(results.items(), markers, colors):\n",
    "        plt.plot(range(1, len(result['cv_scores']) + 1), \n",
    "                result['cv_scores'], \n",
    "                marker=marker,\n",
    "                color=color,\n",
    "                label=scaler, \n",
    "                linewidth=2)\n",
    "    \n",
    "    plt.title('F1 Scores Across CV Folds', fontsize=14)\n",
    "    plt.xlabel('Fold Number', fontsize=12)\n",
    "    plt.ylabel('F1 Score', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # 4. Combined performance plot\n",
    "    plt.subplot(2, 2, 4)\n",
    "    x = np.arange(len(results))\n",
    "    width = 0.35\n",
    "    \n",
    "    cv_means = [result['cv_scores'].mean() for result in results.values()]\n",
    "    cv_stds = [result['cv_scores'].std() for result in results.values()]\n",
    "    test_scores = [result['test_score'] for result in results.values()]\n",
    "    \n",
    "    bars1 = plt.bar(x - width/2, cv_means, width, label='CV Score', color='lightblue')\n",
    "    bars2 = plt.bar(x + width/2, test_scores, width, label='Test Score', color='lightgreen')\n",
    "    \n",
    "    plt.errorbar(x - width/2, cv_means, yerr=cv_stds, fmt='none', color='black', capsize=5)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.3f}',\n",
    "                    ha='center', va='bottom')\n",
    "    \n",
    "    plt.xticks(x, results.keys(), rotation=45)\n",
    "    plt.title('CV vs Test Performance Comparison', fontsize=14)\n",
    "    plt.xlabel('Scaler Type', fontsize=12)\n",
    "    plt.ylabel('F1 Score', fontsize=12)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('f1_score_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nPerformance Summary:\")\n",
    "    print(\"-\" * 50)\n",
    "    for scaler, result in results.items():\n",
    "        print(f\"\\n{scaler.upper()} Scaler:\")\n",
    "        print(f\"CV F1 Score: {result['cv_scores'].mean():.4f}  {result['cv_scores'].std():.4f}\")\n",
    "        print(f\"Test F1 Score: {result['test_score']:.4f}\")\n",
    "    \n",
    "    # Determine best model\n",
    "    best_scaler = max(results.items(), key=lambda x: x[1]['cv_scores'].mean())\n",
    "    print(\"\\nBest Model:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Scaler: {best_scaler[0]}\")\n",
    "    print(f\"CV F1 Score: {best_scaler[1]['cv_scores'].mean():.4f}  {best_scaler[1]['cv_scores'].std():.4f}\")\n",
    "    print(f\"Test F1 Score: {best_scaler[1]['test_score']:.4f}\")\n",
    "\n",
    "def main():\n",
    "    # Load your preprocessed data (using your existing load_and_preprocess_data function)\n",
    "    df = load_and_preprocess_data()\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = df.drop('sought_treatment', axis=1)\n",
    "    y = df['sought_treatment']\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    results = {}\n",
    "    scalers = ['standard', 'minmax', 'log']\n",
    "    \n",
    "    # Perform experiments\n",
    "    for scaler in scalers:\n",
    "        # Create and train pipeline\n",
    "        pipeline = create_pipeline(scaler)\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='f1')\n",
    "        \n",
    "        # Train on full training set and evaluate on test set\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        test_score = f1_score(y_test, pipeline.predict(X_test))\n",
    "        \n",
    "        # Store results\n",
    "        results[scaler] = {\n",
    "            'cv_scores': cv_scores,\n",
    "            'test_score': test_score,\n",
    "            'pipeline': pipeline\n",
    "        }\n",
    "    \n",
    "    # Create plots and print summary\n",
    "    plot_f1_scores(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
